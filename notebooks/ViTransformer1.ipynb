{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer for ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset # wraps an iterable around the dataset\n",
    "from torchvision import datasets    # stores the samples and their corresponding labels\n",
    "from torchvision.transforms import transforms  # transformations we can perform on our dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training \n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self, split='train'):\n",
    "\n",
    "        self.split = split\n",
    "\n",
    "        # data loading\n",
    "        current_directory = os.getcwd()\n",
    "        self.parent_directory = os.path.dirname(current_directory)\n",
    "        train_small_path = os.path.join(self.parent_directory, 'data', 'deepfake-ecg-small', str(self.split) + '.csv')\n",
    "        self.df = pd.read_csv(train_small_path)  # Skip the header row\n",
    "        \n",
    "        # Avg RR interval\n",
    "        # in milli seconds\n",
    "        RR = torch.tensor(self.df['avgrrinterval'].values, dtype=torch.float32)\n",
    "        # calculate HR\n",
    "        self.y = 60 * 1000/RR\n",
    "\n",
    "        # Size of the dataset\n",
    "        self.samples = self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # file path\n",
    "        filename= self.df['patid'].values[index]\n",
    "        asc_path = os.path.join(self.parent_directory, 'data', 'deepfake-ecg-small', str(self.split), str(filename) + '.asc')\n",
    "        \n",
    "        ecg_signals = pd.read_csv( asc_path, header=None, sep=\" \") # read into dataframe\n",
    "        ecg_signals = torch.tensor(ecg_signals.values) # convert dataframe values to tensor\n",
    "        \n",
    "        ecg_signals = ecg_signals.float()\n",
    "        \n",
    "        # Transposing the ecg signals\n",
    "        ecg_signals = ecg_signals/6000 # normalization\n",
    "        ecg_signals = ecg_signals.t() \n",
    "        \n",
    "        qt = self.y[index]\n",
    "        # Retrieve a sample from x and y based on the index\n",
    "        return ecg_signals, qt\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return self.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG dataset\n",
    "train_dataset = ECGDataSet(split='train')\n",
    "validate_dataset = ECGDataSet(split='validate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:560: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# data loader\n",
    "# It allows you to efficiently load and iterate over batches of data during the training or evaluation process.\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=8, shuffle=True, num_workers=20)\n",
    "validate_dataloader = DataLoader(dataset=validate_dataset, batch_size=8, shuffle=False, num_workers=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the tensorboard\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function with tensorbard\n",
    "def trainTB(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    # get the number of batches\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        \n",
    "        # check the shape of pred and y here\n",
    "        if batch == 1:\n",
    "            print(pred.shape)       # this is [8,1]\n",
    "            print(y.shape)          # this is [8]\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    loss_avg = total_loss/num_batches\n",
    "    print(f\"Epoch [{epoch+1}], Average Loss: {loss_avg:.4f}\")\n",
    "    writer.add_scalar(\"Loss/train\", loss_avg, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\"Split image (ECG in our case) into patches and then embed them.\n",
    "\n",
    "    ECG --> 8,5000\n",
    "\n",
    "    Paramerters\n",
    "    ----------\n",
    "    img_size : int\n",
    "        Size of image (ECG) in pixels (samples).    (This is 1D 5000)\n",
    "\n",
    "    patch_size : int\n",
    "\n",
    "    in_chans : int\n",
    "        Number of input channels. (This is 8)\n",
    "\n",
    "    embed_dim : int\n",
    "        Embedding dimension.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    n_patches : int\n",
    "        Number of patches inside of our image.\n",
    "\n",
    "    proj : nn.Conv2d\n",
    "        Convolutional layer that does both the splitting into patches and their embedding.\n",
    "\n",
    "    \"\"\"\n",
    "    # This class is modified so that it works with 1D data.\n",
    "    def __init__(self, img_size=5000, patch_size=50, in_chans=8, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = img_size\n",
    "        patch_size = patch_size\n",
    "        self.n_patches = (img_size // patch_size)\n",
    "\n",
    "        # embed_dim is the output channel size of the convolutional layer.\n",
    "        self.proj = nn.Conv1d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Shape is `(batch_size, in_chans, img_size)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Shape is `(batch_size, n_patches, embed_dim)`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.proj(x) # (batch_size, embed_dim, n_patches)\n",
    "        # I dont think flatten is needed for 1D data.\n",
    "        #x = x.flatten(2) # flatten with 1st 2 dims intact\n",
    "        # (batch_size, embed_dim, n_patches) --> (batch_size, n_patches, embed_dim)\n",
    "        x = x.transpose(1,2)    # (batch_size, n_patches, embed_dim)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (8,5000)  # Modify this according to your input shape\n",
    "# 128 is the batch size, 8 is the number of channels, 5000 is the number of time steps\n",
    "\n",
    "output_size = 1  # Number of output units\n",
    "\n",
    "model = PatchEmbed(input_shape, output_size)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function for linear values (e.g., regression)\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error loss\n",
    "\n",
    "# use Nadam optimizer\n",
    "optimizerN = optim.NAdam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    trainTB(train_dataloader, model, loss_fn, optimizerN, t)\n",
    "print(\"Done!\")\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
