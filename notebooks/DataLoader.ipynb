{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset # wraps an iterable around the dataset\n",
    "from torchvision import datasets    # stores the samples and their corresponding labels\n",
    "from torchvision.transforms import transforms  # transformations we can perform on our dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training \n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataSetPrevious(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        current_directory = os.getcwd()\n",
    "        parent_directory = os.path.dirname(current_directory)\n",
    "        train_small_path = os.path.join(parent_directory, 'data', 'deepfake-ecg-small', 'train.csv')\n",
    "        xy = pd.read_csv(train_small_path)  # Skip the header row\n",
    "        \n",
    "        # QT\n",
    "        self.y = torch.tensor(xy['qt'].values, dtype=torch.float32)\n",
    "        patient_ids = xy['patid'].values\n",
    "\n",
    "        # ECG reports\n",
    "        self.x = []\n",
    "        # read each asc file\n",
    "        for patient_id in patient_ids:\n",
    "            asc_path = os.path.join(parent_directory, 'data', 'deepfake-ecg-small', 'train', str(patient_id)+'.asc')\n",
    "            ecg_data = np.loadtxt(asc_path)\n",
    "            ecg_tensor = torch.from_numpy(ecg_data)\n",
    "            ecg_tensor = ecg_tensor.float()\n",
    "            ecg_tensor = ecg_tensor.permute(1, 0)#.unsqueeze(2)\n",
    "            self.x.append(ecg_tensor)\n",
    "\n",
    "        # Size of the dataset\n",
    "        self.samples = xy.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve a sample from x and y based on the index\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return self.samples\n",
    "    \n",
    "    # def read_file(self, filename):\n",
    "    #     # Read the file and extract the lines\n",
    "    #     with open(filename, 'r') as file:\n",
    "    #         lines = file.readlines()\n",
    "    #         # Initialize an empty matrix\n",
    "    #         matrix = np.empty((8, 5000))\n",
    "    #         # Iterate over each line and fill the matrix\n",
    "    #         for i, line in enumerate(lines):\n",
    "    #         # Split the line into individual values\n",
    "    #             values = line.split()\n",
    "    #             # Convert the values to integers and store them in the matrix\n",
    "    #             matrix[:, i] = np.array(values, dtype=int)\n",
    "\n",
    "    #     return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        current_directory = os.getcwd()\n",
    "        self.parent_directory = os.path.dirname(current_directory)\n",
    "        train_small_path = os.path.join(self.parent_directory, 'data', 'deepfake-ecg-small', 'train.csv')\n",
    "        self.df = pd.read_csv(train_small_path)  # Skip the header row\n",
    "        \n",
    "        # QT\n",
    "        self.y = torch.tensor(self.df['qt'].values, dtype=torch.float32)\n",
    "\n",
    "        # Size of the dataset\n",
    "        self.samples = self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # file path\n",
    "        filename= self.df['patid'].values[index]\n",
    "        asc_path = os.path.join(self.parent_directory, 'data', 'deepfake-ecg-small', 'train', str(filename) + '.asc')\n",
    "        \n",
    "        ecg_signals = pd.read_csv( asc_path, header=None, sep=\" \") # read into dataframe\n",
    "        ecg_signals = torch.tensor(ecg_signals.values) # convert dataframe values to tensor\n",
    "        \n",
    "        ecg_signals = ecg_signals.float()\n",
    "        \n",
    "        # Transposing the ecg signals\n",
    "        ecg_signals = ecg_signals/6000 # normalization\n",
    "        ecg_signals = ecg_signals.t() \n",
    "        \n",
    "        qt = self.y[index]\n",
    "        # Retrieve a sample from x and y based on the index\n",
    "        return ecg_signals, qt\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return self.samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG dataset\n",
    "dataset = ECGDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first data\n",
    "first_data = dataset[0]\n",
    "x, y = first_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-127., -162., -142.,  ...,  -89.,  -39.,  -93.],\n",
       "        [  -1.,    0.,  -46.,  ...,  -18.,   22.,    5.],\n",
       "        [ -33.,   -8.,  -27.,  ...,   44.,   71.,   82.],\n",
       "        ...,\n",
       "        [ -92.,  -86.,  -87.,  ...,   67.,   89.,  105.],\n",
       "        [ -61.,  -67.,  -70.,  ...,   52.,   88.,   26.],\n",
       "        [   2.,  -29.,  -25.,  ...,   69.,  128.,  115.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(434.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "# It allows you to efficiently load and iterate over batches of data during the training or evaluation process.\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load whole dataset with DataLoader\n",
    "# shuffle: shuffle data, good for training\n",
    "# num_workers: faster loading with multiple subprocesses\n",
    "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "\n",
    "# # convert to an iterator and look at one random sample\n",
    "# dataiter = iter(train_loader)\n",
    "# data = next(dataiter)\n",
    "# features, labels = data\n",
    "# print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 5000]) torch.Size([32])\n",
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    print(x.dtype, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(16 * 2500, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_classes = 1  # Number of output classes\n",
    "learning_rate = 0.000000001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: nan\n",
      "Epoch [2/10], Loss: nan\n",
      "Epoch [3/10], Loss: nan\n",
      "Epoch [4/10], Loss: nan\n",
      "Epoch [5/10], Loss: nan\n",
      "Epoch [6/10], Loss: nan\n",
      "Epoch [7/10], Loss: nan\n",
      "Epoch [8/10], Loss: nan\n",
      "Epoch [9/10], Loss: nan\n",
      "Epoch [10/10], Loss: nan\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_inputs, batch_labels in dataloader:\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss after every epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=40000, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1000, out_features=500, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=500, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "# nn.Module --> base class for all neural network modules\n",
    "class NeuralNetwork(nn.Module):\n",
    "    #network archirecture is defined in the init method\n",
    "    def __init__(self):\n",
    "        super().__init__()      #calls the __init__() method of the nn.Module pearent class \n",
    "        #( to ensure that the necessary setup and initialization from the parent class are performed.)\n",
    "        #This is important because the nn.Module class performs important bookkeeping tasks and sets up the internal state of the module.\n",
    "\n",
    "        #self.x are methods below. \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential( # allows to stack multiple layers in a sequential manner\n",
    "            nn.Linear(8*5000,1000 ),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    # method to define the forward pass computation of the model\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)   --> __call__ method is used to call the forward method (IMPORTANT)\n",
    "        #x = self.linear_relu_stack(x) this also can be used\n",
    "        x = self.flatten.forward(x)\n",
    "        logits = self.linear_relu_stack.forward(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)  # get the total number of samples in the dataset\n",
    "    model.train()   #sets the model in training mode (Stets the attribute named Training to True for the model instance) \n",
    "    #Dropout, batch normalization, etc. are used during training.\n",
    "\n",
    "    # iterates over the batches in the dataloader\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # moves the input data to the device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction and loss --> Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        #Backpropagation\n",
    "        loss.backward() # compute the gradients of the model's parameters with respect to the loss function's output\n",
    "        optimizer.step()    #Update the models parameters an optimization algorithm\n",
    "        optimizer.zero_grad()   # Sets all the gradients to zero. If the gradients are not cleared they ll be accumilated.\n",
    "\n",
    "        # prints the progress of the training\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 159991.437500  [    0/10000]\n",
      "loss: 31643.660156  [ 3200/10000]\n",
      "loss: 15995.032227  [ 6400/10000]\n",
      "loss: 22412.558594  [ 9600/10000]\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/projects2/e17-4yp-compreh-ecg-analysis/minicondaInst/envs/test/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 14881.588867  [    0/10000]\n",
      "loss: 9893.944336  [ 3200/10000]\n",
      "loss: 11794.190430  [ 6400/10000]\n",
      "loss: 9825.076172  [ 9600/10000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 10126.932617  [    0/10000]\n",
      "loss: 6501.875000  [ 3200/10000]\n",
      "loss: 6823.670898  [ 6400/10000]\n",
      "loss: 4445.797852  [ 9600/10000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3599.184326  [    0/10000]\n",
      "loss: 5795.050781  [ 3200/10000]\n",
      "loss: 4727.458008  [ 6400/10000]\n",
      "loss: 2762.310547  [ 9600/10000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2013.656250  [    0/10000]\n",
      "loss: 1751.958252  [ 3200/10000]\n",
      "loss: 2036.582397  [ 6400/10000]\n",
      "loss: 1959.443359  [ 9600/10000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1936.314331  [    0/10000]\n",
      "loss: 1604.200317  [ 3200/10000]\n",
      "loss: 1870.130127  [ 6400/10000]\n",
      "loss: 1932.734131  [ 9600/10000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1177.276733  [    0/10000]\n",
      "loss: 1141.282593  [ 3200/10000]\n",
      "loss: 1424.218994  [ 6400/10000]\n",
      "loss: 1321.476562  [ 9600/10000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1396.602295  [    0/10000]\n",
      "loss: 1263.351196  [ 3200/10000]\n",
      "loss: 1086.625854  [ 6400/10000]\n",
      "loss: 989.402100  [ 9600/10000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 917.932007  [    0/10000]\n",
      "loss: 959.422852  [ 3200/10000]\n",
      "loss: 982.674927  [ 6400/10000]\n",
      "loss: 850.657349  [ 9600/10000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 713.403259  [    0/10000]\n",
      "loss: 1182.047363  [ 3200/10000]\n",
      "loss: 806.120605  [ 6400/10000]\n",
      "loss: 714.370300  [ 9600/10000]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 931.387207  [    0/10000]\n",
      "loss: 749.307617  [ 3200/10000]\n",
      "loss: 790.313477  [ 6400/10000]\n",
      "loss: 774.932983  [ 9600/10000]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 839.015442  [    0/10000]\n",
      "loss: 577.199646  [ 3200/10000]\n",
      "loss: 627.595215  [ 6400/10000]\n",
      "loss: 593.578064  [ 9600/10000]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 618.085205  [    0/10000]\n",
      "loss: 914.147522  [ 3200/10000]\n",
      "loss: 700.447449  [ 6400/10000]\n",
      "loss: 600.545654  [ 9600/10000]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 616.109741  [    0/10000]\n",
      "loss: 725.954651  [ 3200/10000]\n",
      "loss: 649.450806  [ 6400/10000]\n",
      "loss: 615.943420  [ 9600/10000]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 727.294434  [    0/10000]\n",
      "loss: 724.978394  [ 3200/10000]\n",
      "loss: 828.970093  [ 6400/10000]\n",
      "loss: 788.285767  [ 9600/10000]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 752.093018  [    0/10000]\n",
      "loss: 563.997681  [ 3200/10000]\n",
      "loss: 486.802734  [ 6400/10000]\n",
      "loss: 516.417847  [ 9600/10000]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 765.858398  [    0/10000]\n",
      "loss: 845.160461  [ 3200/10000]\n",
      "loss: 853.202515  [ 6400/10000]\n",
      "loss: 562.583984  [ 9600/10000]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 579.413086  [    0/10000]\n",
      "loss: 858.763062  [ 3200/10000]\n",
      "loss: 739.291504  [ 6400/10000]\n",
      "loss: 791.640259  [ 9600/10000]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 701.697144  [    0/10000]\n",
      "loss: 805.710388  [ 3200/10000]\n",
      "loss: 596.311584  [ 6400/10000]\n",
      "loss: 505.230652  [ 9600/10000]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 750.325317  [    0/10000]\n",
      "loss: 604.503784  [ 3200/10000]\n",
      "loss: 503.450226  [ 6400/10000]\n",
      "loss: 808.201050  [ 9600/10000]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 410.331543  [    0/10000]\n",
      "loss: 751.983398  [ 3200/10000]\n",
      "loss: 569.990479  [ 6400/10000]\n",
      "loss: 853.297363  [ 9600/10000]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 647.423279  [    0/10000]\n",
      "loss: 495.732422  [ 3200/10000]\n",
      "loss: 474.906921  [ 6400/10000]\n",
      "loss: 467.424866  [ 9600/10000]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 577.718750  [    0/10000]\n",
      "loss: 935.282593  [ 3200/10000]\n",
      "loss: 769.435730  [ 6400/10000]\n",
      "loss: 618.746521  [ 9600/10000]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 700.281494  [    0/10000]\n",
      "loss: 677.337402  [ 3200/10000]\n",
      "loss: 1017.968201  [ 6400/10000]\n",
      "loss: 581.155518  [ 9600/10000]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1103.847412  [    0/10000]\n",
      "loss: 417.471100  [ 3200/10000]\n",
      "loss: 533.025024  [ 6400/10000]\n",
      "loss: 634.036987  [ 9600/10000]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 721.696777  [    0/10000]\n",
      "loss: 464.578217  [ 3200/10000]\n",
      "loss: 653.220825  [ 6400/10000]\n",
      "loss: 711.664978  [ 9600/10000]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 492.961304  [    0/10000]\n",
      "loss: 579.563843  [ 3200/10000]\n",
      "loss: 566.866638  [ 6400/10000]\n",
      "loss: 636.329224  [ 9600/10000]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 768.037781  [    0/10000]\n",
      "loss: 721.017212  [ 3200/10000]\n",
      "loss: 490.256714  [ 6400/10000]\n",
      "loss: 575.430847  [ 9600/10000]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 596.977722  [    0/10000]\n",
      "loss: 635.018311  [ 3200/10000]\n",
      "loss: 524.765869  [ 6400/10000]\n",
      "loss: 759.564026  [ 9600/10000]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1003.104187  [    0/10000]\n",
      "loss: 792.589600  [ 3200/10000]\n",
      "loss: 563.698486  [ 6400/10000]\n",
      "loss: 512.792725  [ 9600/10000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 425.417511  [    0/10000]\n",
      "loss: 456.488037  [ 3200/10000]\n",
      "loss: 600.526978  [ 6400/10000]\n",
      "loss: 648.967285  [ 9600/10000]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 721.649170  [    0/10000]\n",
      "loss: 614.504028  [ 3200/10000]\n",
      "loss: 576.974121  [ 6400/10000]\n",
      "loss: 703.724243  [ 9600/10000]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 570.639771  [    0/10000]\n",
      "loss: 612.325073  [ 3200/10000]\n",
      "loss: 526.089355  [ 6400/10000]\n",
      "loss: 555.528442  [ 9600/10000]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 623.757751  [    0/10000]\n",
      "loss: 626.184937  [ 3200/10000]\n",
      "loss: 608.288086  [ 6400/10000]\n",
      "loss: 380.564697  [ 9600/10000]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 925.012329  [    0/10000]\n",
      "loss: 514.286255  [ 3200/10000]\n",
      "loss: 529.348633  [ 6400/10000]\n",
      "loss: 566.651367  [ 9600/10000]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 443.049744  [    0/10000]\n",
      "loss: 589.979858  [ 3200/10000]\n",
      "loss: 458.020111  [ 6400/10000]\n",
      "loss: 850.249146  [ 9600/10000]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 588.893921  [    0/10000]\n",
      "loss: 508.290558  [ 3200/10000]\n",
      "loss: 543.256775  [ 6400/10000]\n",
      "loss: 436.216736  [ 9600/10000]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 632.530396  [    0/10000]\n",
      "loss: 365.772949  [ 3200/10000]\n",
      "loss: 430.716400  [ 6400/10000]\n",
      "loss: 816.355347  [ 9600/10000]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 407.043610  [    0/10000]\n",
      "loss: 405.584900  [ 3200/10000]\n",
      "loss: 622.737671  [ 6400/10000]\n",
      "loss: 573.501831  [ 9600/10000]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 697.748596  [    0/10000]\n",
      "loss: 706.802979  [ 3200/10000]\n",
      "loss: 381.176392  [ 6400/10000]\n",
      "loss: 442.577057  [ 9600/10000]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 443.651306  [    0/10000]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader, model, loss_fn, optimizer)\n",
    "    #test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
